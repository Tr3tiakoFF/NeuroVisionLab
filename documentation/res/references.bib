@misc{emnist,
  author = {Cohen, Gregory and Afshar, Saeed and Tapson, Jonathan and van Schaik, Andr},
  title = {EMNIST: Extending MNIST to handwritten letters},
  year = {2017},
  howpublished = {\url{https://www.nist.gov/itl/iad/image-group/emnist-dataset}}
}

@article{cohen2017emnist,
  title={EMNIST: an extension of MNIST to handwritten letters},
  author={Cohen, Gregory and Afshar, Saeed and Tapson, Jonathan and van Schaik, Andr{\'e}},
  journal={arXiv preprint arXiv:1702.05373},
  year={2017},
  url={http://arxiv.org/abs/1702.05373}
}

@misc{kmnist,
  author = {Clanuwat, Tanakorn and Bober-Irizar, Pablo and Kitamoto, Atsushi and Lamb, Alex and Yamamoto, Kazuaki and Ha, David},
  title = {KMNIST: Kuzushiji-MNIST, a handwritten Japanese character dataset},
  year = {2018},
  howpublished = {\url{https://github.com/rois-codh/kmnist}}
}

@article{clanuwat2018deep,
  title={Deep learning for classical Japanese literature},
  author={Clanuwat, Thanard and Bui, Phuoc and Madhawa, Kasun and Gan, Chay and Shimoda, Wataru and Aramaki, Eri and Iwamura, Masashi},
  journal={arXiv preprint arXiv:1812.01718},
  year={2018},
  url={https://arxiv.org/abs/1812.01718}
}

@misc{svhn,
  author = {Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y.},
  title = {SVHN: Street View House Numbers Dataset},
  year = {2011},
  howpublished = {\url{http://ufldl.stanford.edu/housenumbers/}}
}

@article{resnet,
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  title = {Deep Residual Learning for Image Recognition},
  journal = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year = {2016},
  pages = {770-778},
  doi = {10.1109/CVPR.2016.90}
}

@article{mobilenetv2,
  author = {Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Leonid and Chen, Liang-Chieh},
  title = {MobileNetV2: Inverted Residuals and Linear Bottlenecks},
  journal = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year = {2018},
  pages = {4510-4520},
  doi = {10.1109/CVPR.2018.00474}
}

@article{vit,
  author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  title = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  journal = {International Conference on Learning Representations (ICLR)},
  year = {2021},
  url = {https://openreview.net/forum?id=YicbFdNTTy}
}

@misc{pytorch_models,
  author = {PyTorch Contributors},
  title = {Torchvision Models Documentation},
  howpublished = {\url{https://pytorch.org/vision/stable/models.html}},
  year = {2025},
  note = {Accessed: 2025-05-16}
}

@misc{huggingface_vit,
  author = {Hugging Face},
  title = {Vision Transformer — Transformers Documentation},
  howpublished = {\url{https://huggingface.co/docs/transformers/model_doc/vit}},
  year = {2025},
  note = {Accessed: 2025-05-16}
}

@misc{lucidrains_vit_pytorch,
  author = {Phil Wang},
  title = {vit-pytorch: Vision Transformer implemented in Pytorch},
  howpublished = {\url{https://github.com/lucidrains/vit-pytorch}},
  year = {2025},
  note = {Accessed: 2025-05-16}
}

@misc{neurovisionlab2025,
  author = {Tretiakov, Yehor (Tr3tiakoFF)},
  title        = {NeuroVisionLab: Репозиторій з кодом для досліджень у сфері штучних нейронних мереж},
  howpublished = {\url{https://github.com/Tr3tiakoFF/NeuroVisionLab}},
  year         = {2025},
  note         = {Доступ 16 травня 2025}
}

@misc{imagenet21k,
  title        = {ImageNet Large Scale Visual Recognition Challenge (ILSVRC)},
  howpublished = {\url{http://image-net.org/challenges/LSVRC/}},
  note         = {Accessed: 2025-05-16}
}

@article{dosovitskiy2020vit,
  author    = {Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
  title     = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  journal   = {arXiv preprint arXiv:2010.11929},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.11929}
}

@misc{googlejft300m,
  author       = {{Google AI}},
  title        = {Scaling Vision Transformers},
  howpublished = {\url{https://ai.googleblog.com/2021/05/scaling-vision-transformers.html}},
  note         = {Accessed: 2025-05-16}
}

@article{mahajan2018exploring,
  author    = {Dhruv Mahajan and Ross Girshick and Vignesh Ramanathan and Kaiming He and Manohar Paluri and Yixuan Li and Ashwin Bharambe and Laurens van der Maaten},
  title     = {Exploring the Limits of Weakly Supervised Pretraining},
  journal   = {arXiv preprint arXiv:1805.00932},
  year      = {2018},
  url       = {https://arxiv.org/abs/1805.00932}
}

@article{convit2021,
  author  = {Thomas De Vries and Hugo Castrillón and Jakob Uszkoreit and Oriol Vinyals},
  title   = {ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases},
  journal = {arXiv preprint arXiv:2103.10697},
  year    = {2021},
  url     = {https://arxiv.org/abs/2103.10697}
}

@article{bridginggap2022,
  author  = {Chen, Zihang and others},
  title   = {Bridging the Gap Between Vision Transformers and Convolutional Neural Networks on Small Datasets},
  journal = {arXiv preprint arXiv:2210.05958},
  year    = {2022},
  url     = {https://arxiv.org/abs/2210.05958}
}

@article{vaswani2017attention,
  author    = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and
               Llion Jones and Aidan N. Gomez and {\L}ukasz Kaiser and Illia Polosukhin},
  title     = {Attention is All You Need},
  journal   = {Advances in Neural Information Processing Systems},
  volume    = {30},
  year      = {2017},
  url       = {https://arxiv.org/abs/1706.03762}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016},
  url={https://doi.org/10.1109/CVPR.2016.90}
}

@article{howard2017mobilenets,
  title={MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications},
  author={Howard, Andrew G. and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
  journal={arXiv preprint arXiv:1704.04861},
  year={2017},
  url={https://arxiv.org/abs/1704.04861}
}

@inproceedings{sandler2018mobilenetv2,
  title={MobileNetV2: Inverted Residuals and Linear Bottlenecks},
  author={Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Liang-Chieh and Chen, Bo},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4510--4520},
  year={2018},
  url={https://doi.org/10.1109/CVPR.2018.00474}
}

@inproceedings{szegedy2017inception,
  title={Inception-v4, inception-resnet and the impact of residual connections on learning},
  author={Szegedy, Christian and Ioffe, Sergey and Vanhoucke, Vincent and Alemi, Alexander},
  booktitle={Thirty-first AAAI conference on artificial intelligence},
  year={2017},
  url={https://arxiv.org/abs/1602.07261}
}